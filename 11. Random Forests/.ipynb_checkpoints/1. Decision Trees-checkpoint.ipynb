{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "Decision trees are a powerful prediction method and extremely popular.\n",
    "\n",
    "They are popular because the final model is so easy to understand by practicioners and domain experts alike. The final decision tree can explain exactly why a specific prediction was made, making it very attractive for operational use.\n",
    "\n",
    "Decision trees also provide the foundation for more advanced ensemble methods such as bagging, random forests and gradient boosting.\n",
    "\n",
    "In this tutorial, you will discover how to implement the Classification And Regression Tree algorithm from scratch with Python.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "-  How to calculate and evaluate candidate split points in a data.\n",
    "-  How to arrange splits into a decision tree structure.\n",
    "-  How to apply the classification and regression tree algorithm to a real problem.\n",
    "\n",
    "Let's get started.\n",
    "\n",
    "## Descriptions\n",
    "\n",
    "This section provides a brief introduction to the Classification and Regression Tree algorithm and the Banknote dataset used in this tutorial.\n",
    "\n",
    "### Classification and Regression Trees\n",
    "\n",
    "Classification or Regression Trees or CART for short is an acronym introduced by Leo Breiman to refer to Decision Tree algorithms that can be used for classification or regression predictive modeling problems.\n",
    "\n",
    "We will focus on using CART for classification in this tutorial.\n",
    "\n",
    "The representation of the CART model is a binary tree. This is the same binary tree from algorithms and data structures, nothing too fancy (each node can have zero, one or two child nodes).\n",
    "\n",
    "A node represents a single input variable (X) and a split point on that variable, assuming the variable is numeric. The leaf nodes (also called terminal nodes) of the tree contain an output variable (y) which is used to make a prediction.\n",
    "\n",
    "Once created, a tree can be navigated with a new row of data following each branch with the splits until a final prediction is made.\n",
    "\n",
    "Creating a binary decision tree is actually a process of dividing up the input space. A greedy approach is used to divide the space, called Recursive Binary Splitting. This is a numerical procedure where all the values are lined up and different split points are tried and tested using a cost function.\n",
    "\n",
    "The split with the best cost (lowest cost because we minimize cost) is selected. All input variables and all possible split points are evaluated and chosen in a greedy manner based on the cost function.\n",
    "\n",
    "-  __Regression__: The cost function that is minimized to choose split points is the sum squared error across all training samples that fall within the rectangle.\n",
    "-  __Classification__: The Gini cost function is used which provides an indication of how pure the nodes are, where node purity refers to how mixed the training data assigned to each node is.\n",
    "\n",
    "Splitting continues until nodes contain a minimum number of training examples or a maximum tree depth is reached.\n",
    "\n",
    "### Banknote Dataset\n",
    "\n",
    "The banknote dataset involves predicting whether a given banknote is authentic given a number of measures taken from a photograph.\n",
    "\n",
    "The dataset contains 1,372 rows with 5 numeric variables. It is a classification problem with two classes (binary classification).\n",
    "\n",
    "Below provides a list of the five variables in the dataset.\n",
    "1. Variance of Wavelet Transformed image (continuous).\n",
    "2. Skewness of Wavelet Transformed image (continuous).\n",
    "3. Kurtosis of Wavelet Transformed image (continuous).\n",
    "4. Entropy of image (continuous).\n",
    "5. Class (integer)\n",
    "\n",
    "Below is a sample of the first 5 rows in the dataset\n",
    "```\n",
    " 3.6216,8.6661,-2.8073,-0.44699,0\n",
    " 4.5459,8.1674,-2.4586,-1.4621,0\n",
    " 3.866,-2.6383,1.9242,0.10645,0\n",
    " 3.4566,9.5228,-4.0112,-3.5944,0\n",
    " 0.32924,-4.4552,4.5718,-0.9888,0\n",
    "```\n",
    "\n",
    "Using the Zero Rule Algorithm to predict the most common class value, the baseline accuracy on the problem is about 50%.\n",
    "\n",
    "You can learn more and download the dataset from the [UCI Machine Learning Repository.](http://archive.ics.uci.edu/ml/datasets/banknote+authentication)\n",
    "\n",
    "Download the dataset and place it in your current working directory with the filename __data_banknote_authentication.csv__.\n",
    "\n",
    "## Tutorial\n",
    "\n",
    "This tutorial is broken down into 5 parts:\n",
    "1. Gini Index.\n",
    "2. Create Split.\n",
    "3. Build a Tree.\n",
    "4. Make a Prediction.\n",
    "5. Banknote Case Study.\n",
    "\n",
    "These steps will give you the foundation that you need to implement the CART algorithm from scratch and apply it to your own predictive modeling problems.\n",
    "\n",
    "### 1. Gini Index\n",
    "\n",
    "The Gini index is the name of the cost function used to evaluate splits in the dataset.\n",
    "\n",
    "A split in the dataset involves one input attribute and one value for that attribute. It can be used to divide training patterns into two groups of rows.\n",
    "\n",
    "A Gini score gives an idea of how good a split is by how mixed the classes are in the two groups created by the split. A perfect separation results in a Gini score of 0, whereas the worst case split that results in 50/50 classes in each group, results in a Gini score of 0.5 (for a 2 class problem).\n",
    "\n",
    "Calculating Gini is best demonstrated with an example.\n",
    "\n",
    "We have two groups of data with 2 rows in each group. The rows in the first group all belong to class 0 and the rows in the second group belong to class 1, so it's a perfect split.\n",
    "\n",
    "We first need to calculate the proportion of classes in each group.\n",
    "\n",
    "$$\\text{proportion} = \\frac{\\text{count(class value)}}{\\text{count(rows)}}$$\n",
    "\n",
    "The proportion for this example would be:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\text{Group 1 class 0} = 2 / 2 = 1\\\\\n",
    "\\text{Group 1 class 1} = 0 / 2 = 0\\\\\n",
    "\\text{Group 2 class 0} = 0 / 2 = 0\\\\\n",
    "\\text{Group 2 class 1} = 2 / 2 = 1\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "Gini is then calculated for each child node as follows:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\text{Gini index} &= \\sum(\\text{proportion} * (1.0 - \\text{proportion}))\\\\\n",
    "&= 1.0 - \\sum(\\text{proportion}^2)\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "The Gini index for each group must then be weighted by the size of the group, relative to all of the samples in the parent, e.g. all samples that are currently being grouped. We can add this weighting to the Gini calculation for a group as follows:\n",
    "\n",
    "$$\\text{Gini index} = (1.0 - \\sum(\\text{proportion}^2)) * \\frac{\\text{group size}}{\\text{total samples}}$$\n",
    "\n",
    "In this example, the Gini scores for each group are calculated as follows:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\text{Gini(group 1)} &= (1 - (1^2 + 0^2)) * 2/4\\\\\n",
    "&= 0 * 0.5\\\\\n",
    "&= 0\\\\\n",
    "\\text{Gini(group 2)} &= (1 - (0^2 + 1^2)) * 2/4\\\\\n",
    "&= 0 * 0.5\\\\\n",
    "&= 0\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "The scores are then added across each child node at the split point to give a final Gini score for the split point that can be compared to other candidate split points.\n",
    "\n",
    "The Gini for this split point would then be calculated as 0.0 + 0.0 or a perfect Gini score of 0.0.\n",
    "\n",
    "Below is a function named __gini_index()__ that calculates the Gini index for a list of groups and a list of known class values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
