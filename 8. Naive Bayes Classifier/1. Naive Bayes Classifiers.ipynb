{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers\n",
    "\n",
    "Naive Bayes classifiers are a collection of classification algorithms based on the __Bayes' Theorem__.\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    "Where $A$ and $B$ are events and $P(B) \\neq 0$.\n",
    "-  $P(A|B)$ is a conditional probability: the likelihood of event $A$ occurring given that $B$ is true.\n",
    "-  $P(B|A)$ is also a conditional probability: the likelihood of event $B$ occurring given that $A$ is true.\n",
    "-  $P(A)$ and $P(B)$ are the probabilities of observing $A$ and $B$ independently of each other; this is known as the marginal probability.\n",
    "\n",
    "It is not a single algorithms but a family of algorithms where all of them share a common principle, i.e. every pair of features being classified is independent of each other. This is a strong assumption but results in a fast and effective method.\n",
    "\n",
    "The probability of a class value given a value of an attribute is called the conditional probability. By multiplying the conditional probabilities together for each attribute for a given class value, we have a probability of a data instance belonging to that class.\n",
    "\n",
    "To make a prediction we can calculate probabilities of the instance belonging to each class and select the class value with the highest probability.\n",
    "\n",
    "## Predict the Onset of Diabetes\n",
    "\n",
    "The test problem we will use in this tutorial is the Pima Indians Diabetes problem.\n",
    "\n",
    "This problem is comprise of 768 observations of medical details for Pima Indians patients. The records describe instantaneous measurements taken from the patients such as their age, the number of times pregnant and blood workup. All patients are women aged 21 or older. All attributes are numeric, and their units vary from attribute to attribute.\n",
    "\n",
    "Each record has a class value that indicates whether the patient suffered an onset of diabetes within 5 years of when the measurements were taken (1) or not (0). This is a standard dataset that has been studied a lot in machine learning literature. A good prediction accuracy is 70%-76%.\n",
    "\n",
    "Below is a sample of from the _pima-indians.data.csv_ file to get a sense of the data we will be working with:\n",
    "```\n",
    " 6,148,72,35,0,33.6,0.627,50,1\n",
    " 1,85,66,29,0,26.6,0.351,31,0\n",
    " 8,183,64,0,0,23.3,0.672,32,1\n",
    " 1,89,66,23,94,28.1,0.167,21,0\n",
    " 0,137,40,35,168,43.1,2.288,33,1\n",
    "```\n",
    "\n",
    "This tutorial is broken down into the following steps:\n",
    "1. __Handle Data__: Load the data from the CSV file and split it into training and test datasets.\n",
    "2. __Summarize Data__: Summarize the properties in the training dataset so that we can calculate probabilities and make predictions.\n",
    "3. __Make a Prediction__: Use the summaries of the dataset to generate a single prediction.\n",
    "4. __Make Predictions__: Generate predictions given a test dataset and a summarized training dataset.\n",
    "5. __Evaluate Accuracy__: Evaluate the accuracy of predictions made for a test dataset as the percentage correct out of all predictions made.\n",
    "6. __Tie It Together__: Use all of the code elements to present a complete and standalone implementation of the Naive Bayes algorithm.\n",
    "\n",
    "### 1. Handle Data\n",
    "\n",
    "The first thing we need to do is to read our data file. The data is in CSV format without a header line or any quotes. We also need to convert the attributes that were loaded as strings into numbers so that we can work with them. Below is the __read_csv()__ function for loading the Pima Indians dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    with open(filename) as f:\n",
    "        dataset = [[float(x) for x in line.split(',')] for line in f]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test this function by loading the Pima Indians dataset and printing the number of data instances that were loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file \"pima-indians-diabetes.data.csv\" with 768 rows\n"
     ]
    }
   ],
   "source": [
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "dataset = read_csv(filename)\n",
    "print('Loaded data file \"{0}\" with {1} rows'.format(filename, len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to split the data into a training dataset that Naive Bayes can use to make predictions and a test dataset that we can use to evaluate the accuracy of the model. We need to split the dataset randomly into train and test datasets with a ratio of 67% train and 33% test (this is a common ratio for testing an algorithm on a dataset).\n",
    "\n",
    "Below is the __train_test_split()__ function that will split a given dataset into a given split ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_test_split(dataset, split_ratio):\n",
    "    train_size = int(len(dataset) * split_ratio)\n",
    "    train = []\n",
    "    test = list(dataset)\n",
    "    while len(train) < train_size:\n",
    "        index = random.randrange(len(test))\n",
    "        train.append(test.pop(index))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test this out by defining a mock dataset with 5 instances, split it into training and testing datasets and print them out to see which data instances ended up where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 5 rows into train with [[4], [5], [3]] and test with [[1], [2]]\n"
     ]
    }
   ],
   "source": [
    "dataset = [[1], [2], [3], [4], [5]]\n",
    "split_ratio = 0.67\n",
    "train, test = train_test_split(dataset, split_ratio)\n",
    "print('Split {0} rows into train with {1} and test with {2}'.format(len(dataset), train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summarize Data\n",
    "\n",
    "The Naive Bayes model is comprised of a summary of the data in the training dataset. This summary is then used when making predictions.\n",
    "\n",
    "The summary of the training data collected involves the mean and the standard deviation for each attribute, by class value. For example, if there are two class values and 7 numerical attributes, then we need a mean and standard deviation for each attribute (7) and class value combination, that is 14 attribute summaries.\n",
    "\n",
    "These are required when making predictions to calculate the probability of specific attribute values belonging to each class value.\n",
    "\n",
    "We can break the preparation of this summary data down into the following sub-tasks:\n",
    "1. Separate Data By Class\n",
    "2. Calculate Mean\n",
    "3. Calculate Standard Deviation\n",
    "4. Summarize Dataset\n",
    "5. Summarize Attributes By Class\n",
    "\n",
    "#### Separate Data By Class\n",
    "\n",
    "The first task is to separate the training dataset instances by class value so that we can calculate statistics for each class. We can do that by creating a map of each class value to a list of instances that belong to that class and sort the entire dataset of instances into the appropriate lists.\n",
    "\n",
    "The __separate_by_class()__ function below does just this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_by_class(dataset):\n",
    "    separated = {}\n",
    "    for data in dataset:\n",
    "        if data[-1] not in separated:\n",
    "            separated[data[-1]] = []\n",
    "        separated[data[-1]].append(data)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the function assumes that the last attribute (-1) is the class value. The function returns a map of class values to lists of data instances.\n",
    "\n",
    "We can test this function with some sample data, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separated instances: {1: [[1, 20, 1], [3, 22, 1]], 0: [[2, 21, 0]]}\n"
     ]
    }
   ],
   "source": [
    "dataset = [[1, 20, 1], [2, 21, 0], [3, 22, 1]]\n",
    "separated = separate_by_class(dataset)\n",
    "print('Separated instances: {0}'.format(separated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Mean\n",
    "\n",
    "We need to calculate the mean of each attribute for a class value. The mean is the central middle or central tendency of the data, and we will use it as the middle of our Gaussian distribution when calculating probabilities.\n",
    "\n",
    "We also need to calculate the standard deviation of each attribute for a class value. The standard deviation describes the variation of spread of the data, and we will use it to characterize the expected spread of each attribute in our Gaussian distribution when calculating probabilities.\n",
    "\n",
    "The standard deviation is calculated as the square root of the variance. The variance is calculated as the average of the squared differences for each attribute value from the mean. Note we are using the $N-1$ method, which subtracts 1 from the number of attribute values when calculating the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers) / float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([(x - avg)**2 for x in numbers]) / float(len(numbers) - 1)\n",
    "    return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test this by taking the mean of the numbers from 1 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of [1, 2, 3, 4, 5]: mean = 3.0, stdev = 1.5811388300841898\n"
     ]
    }
   ],
   "source": [
    "numbers = [1, 2, 3, 4, 5]\n",
    "print('Summary of {0}: mean = {1}, stdev = {2}'.format(numbers, mean(numbers), stdev(numbers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
