{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Data Visualization\n",
    "\n",
    "Feature Selection is the process where you automatically or manually select those features which contribute most to your prediction variable or output in which you are interested in.\n",
    "\n",
    "Having irrelevant features in your data can decrease the accuracy of the models and make your model learn based on irrelevant features.\n",
    "\n",
    "<img src='files/img/featureselection.jpg'>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "One of the best ways I use to learn machine learning is by benchmarking myself against the best data scientists in competitions. It gives you a lot of insight into how you perform against the best on a level playing field.\n",
    "\n",
    "Initially, I used to believe that machine learning is going to be all about algorithms - know which one to apply when and you will come out on top. When I got there, I realized that was not the case - the winners were using the same algorithms which a lot of other people were using.\n",
    "\n",
    "Next, I thought surely these people would have better/superior machines. I discover that is not the case. I saw competitions being won using a MacBook Air, which is not the best computational machine. Over time, I realized that there are 2 things which distinguish winners from others in most of the cases: __Feature Creation__ and __Feature Selection__.\n",
    "\n",
    "In other words, it boils down to creating variables which capture hidden business insights and then making the right choices about which variable to choose for your predictive models! Sadly or thankfully, both these skills require a ton of practice. There is also some art involved in creating new features - some people have a knack of finding trends where other people struggle.\n",
    "\n",
    "## Importance of Feature Selection in Machine Learning\n",
    "\n",
    "The importance of feature selection can best be recognized when you are dealing with a dataset that contains a vast number of features. This type of dataset is often referred to as a _high dimensional_ dataset. Now, with this high dimensionality, comes a lot of problems such as - this high dimensionality will significantly increase the training time of your machine learning model, it can make your model very complicated which in turn may lead to Overfitting.\n",
    "\n",
    "Often in a high dimensional feature set, there remains several features which are redundant, meaning these features are nothing but extensions of the other essential features. These redundant features do not effectively contribute to the model training as well. So, clearly, there is a need to extract the most important and the most relevant features for a dataset in order to get the most effective predictive modeling performance.\n",
    "\n",
    "_\"The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data.\"_\n",
    "\n",
    "- [An Introduction to Variable and Feature Selection](https://www.datacamp.com/community/tutorials/feature-selection-python)\n",
    "\n",
    "Now let's understand the difference between __dimensionality reduction__ and __feature selection__.\n",
    "\n",
    "Sometimes, feature selection is mistaken with dimensionality reduction. But they are different. Feature selection is different from dimensionality reduction. Both methods tend to reduce the number of attributes in the dataset, but a dimensionality reduction method does so by creating new combinations of attributes (sometimes known as feature transformation), whereas feature selection methods include and exclude attributes present in the data without changing them.\n",
    "\n",
    "Some examples of dimensionality reduction methods are Principal Component Analysis, Singular Value Decomposition, Linear Discriminant Analysis, etc.\n",
    "\n",
    "Let me summarize the importance of feature selection for you:\n",
    "-  It enables the machine learning algorithm to train faster\n",
    "-  It reduces the complexity of a model and makes it easier to interpret.\n",
    "-  It improves the accuracy of a model if the right subset is chosen.\n",
    "-  It reduces Overfitting.\n",
    "\n",
    "In the next section, you will study the different types of general feature selection methods - Filter methods, Wrapper methods, and Embedded methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
