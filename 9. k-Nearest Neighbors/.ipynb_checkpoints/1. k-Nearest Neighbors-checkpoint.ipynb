{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors\n",
    "\n",
    "The k-Nearest Neighbors algorithm (or kNN for short) is an easy algorithm to understand and to implement, and a powerful tool to have at your disposal.\n",
    "\n",
    "In this tutorial you will implement the k-Nearest Neighbors algorithm from scratch in Python. The implementation will be specific for classification problems and will be demonstrated using the Iris flowers classification problem.\n",
    "\n",
    "This tutorial is for you if you are a Python programmer, or a programmer who can pick-up Python quickly, and you are interested in how to implement k-Nearest Neighbors from scratch.\n",
    "\n",
    "<img src=\"files/k-Nearest-Neighbors-algorithm.png\">\n",
    "\n",
    "## What is k-Nearest Neighbors\n",
    "\n",
    "The model for kNN is the entire training dataset. When a prediction is required for an unseen data instance, the kNN algorithm will search through the training dataset for the k-most similar instances. The prediction attribute of the most similar instances is summarized and returned as the prediction for the unseen instance.\n",
    "\n",
    "The similarity measure is dependent on the type of data. For real-valued data, the Euclidean distance can be used. Other types of data such as categorical or binary data, Hamming distance can be used.\n",
    "\n",
    "In the case of regression problems, the average of the predicted attribute may be returned. In the case of classification, the most prevalent class may be returned.\n",
    "\n",
    "## How does k-Nearest Neighbors Work\n",
    "\n",
    "The kNN algorithm belongs to the family of instance-based, competitive learning and lazy learning algorithms.\n",
    "\n",
    "Instance-based algorithms are those algorithms that model the problem using data instances (or rows) in order to make predictive decisions. The kNN algorithm is an extreme form of instance-based methods because all training observations are retained as part of the model.\n",
    "\n",
    "It is a competitive learning algorithm, because it internally uses competition between model elements (data instances) in order to make a predictive decision. The objective similarity measure between data instances causes each data instance to compete to \"win\" or be most similar to a given unseen data instance and contribute to a prediction.\n",
    "\n",
    "Lazy learning refers to the fact that the algorithm does not build a model until the time that a prediction is required. It is lazy because it only does work at the last second. This has the benefit of only including data relevant to the unseen data, called a localized model. A disadvantage is that it can be computationally expensive to repeat the same or similar searches over larger training datasets.\n",
    "\n",
    "Finally, kNN is powerful because it does not assume anything about the data, other than a distance measure that can be calculated consistently between any two instances. As such, it is called non-parametric or non-linear as it does not assume a functional form\n",
    "\n",
    "## Classify Flowers Using Measurements\n",
    "\n",
    "The test problem we will be using in this tutorial is iris classification.\n",
    "\n",
    "The problem is comprised of 150 observations of iris flowers from three different species. There are 4 measurements of given flowers: sepal length, sepal width, petal length and petal width, all in the same unit of centimeters. The predicted attribute is the species, which is one of setosa, versicolor or virginica.\n",
    "\n",
    "It is a standard dataset where the species is known for all instances. As such we can split the data into training and test datasets and use the results to evaluate our algorithm implementation. Good classification accuracy on this problem is above 90% correct, typically 96% or better.\n",
    "\n",
    "-  [Download the Iris Flowers Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data)\n",
    "\n",
    "Save the file in your current working directory with the file name \"_iris.data_\".\n",
    "\n",
    "## How to implement k-Nearest Neighbors in Python\n",
    "\n",
    "This tutorial is broken down into the following steps:\n",
    "\n",
    "1. __Handle Data__: Open the dataset from CSV and split into test/train datasets.\n",
    "2. __Similarity__: Calculate the distance between two data instances.\n",
    "3. __Neighbors__: Locate k-most similar data instances.\n",
    "4. __Response__: Generate a response from a set of data instances.\n",
    "5. __Accuracy__: Summarize the accuracy of predictions.\n",
    "6. __Main__: Tie it all together.\n",
    "\n",
    "### 1. Handle Data\n",
    "\n",
    "The first thing we need to do is load our data file. The data is in CSV format without a header line or any quotes. We also need to convert the attributes that were loaded as strings into numbers so that we can work with them. Below is the __read_csv()__ function for loading the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    with open(filename) as f:\n",
    "        dataset = [[x for x in line.split(',')] for line in f if line.strip()]\n",
    "        for row in dataset:\n",
    "            for i in range(len(row)-1):\n",
    "                row[i] = float(row[i])\n",
    "            row[-1] = row[-1].rstrip()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test this function by loading the Iris dataset and printing the number of data instances that were loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file \"iris.data\" with 150 rows\n"
     ]
    }
   ],
   "source": [
    "filename = 'iris.data'\n",
    "dataset = read_csv(filename)\n",
    "print('Loaded data file \"{0}\" with {1} rows'.format(filename, len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to split the data into a training dataset that kNN can use to make predictions and a test dataset that we can use to evaluate the accuracy of the model. We need to split the dataset randomly into train and test datasets with a ratio of 67% train and 33% test (this is a common ratio for testing an algorithm on a dataset).\n",
    "\n",
    "Below is the __train_test_split()__ function that will split a given dataset into a given split ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_test_split(dataset, split_ratio):\n",
    "    train_size = int(len(dataset) * split_ratio)\n",
    "    train = []\n",
    "    test = list(dataset)\n",
    "    while len(train) < train_size:\n",
    "        index = random.randrange(len(test))\n",
    "        train.append(test.pop(index))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the iris flowers dataset CSV file to the local directory. We can test this function out with our iris dataset, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 150 rows into train = 100 and test = 50 rows\n"
     ]
    }
   ],
   "source": [
    "dataset = read_csv('iris.data')\n",
    "train, test = train_test_split(dataset, 0.67)\n",
    "print('Split %d rows into train = %d and test = %d rows'\n",
    "      % (len(dataset), len(train), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
